{"cells":[{"cell_type":"markdown","source":["# Step 3B: Model Scoring evaluation\n\nUsing the results data set constructed in the `3b_model_scoring` Jupyter notebook, this notebook loads the data scores the observations. \n\n**Note:** This notebook will take about 1 minutes to execute all cells, depending on the compute configuration you have setup."],"metadata":{}},{"cell_type":"code","source":["# import the libraries\n\n# For some data handling\nimport numpy as np\nfrom pyspark.ml import PipelineModel\n# for creating pipelines and model\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n\n# The scoring uses the same feature engineering script used to train the model\nresults_table = 'results_output'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["dbutils.widgets.removeAll()\ndbutils.widgets.text(\"results_data\", results_table)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# make predictions. The Pipeline does all the same operations on the test data\nsqlContext.refreshTable(dbutils.widgets.get(\"results_data\")) \npredictions =  spark.table(dbutils.widgets.get(\"results_data\"))\n\n# Create the confusion matrix for the multiclass prediction results\n# This result assumes a decision boundary of p = 0.5\nconf_table = predictions.stat.crosstab('indexedLabel', 'prediction')\nconfuse = conf_table.toPandas()\nconfuse.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">10</span><span class=\"ansired\">]: </span>\n  indexedLabel_prediction    0.0  1.0  2.0  3.0  4.0\n0                     0.0  61914   34   15   42    5\n1                     1.0   1094  394    1    1    1\n2                     2.0    735    2  257    2    0\n3                     3.0    582    0    0  293    0\n4                     4.0    485    2    1    3  171\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["The confusion matrix lists each true component failure in rows and the predicted value in columns. Labels numbered 0.0 corresponds to no component failures. Labels numbered 1.0 through 4.0 correspond to failures in one of the four components in the machine. As an example, the third number in the top row indicates how many days we predicted component 2 would fail, when no components actually did fail. The second number in the second row, indicates how many days we correctly predicted a component 1 failure within the next 7 days.\n\nWe read the confusion matrix numbers along the diagonal as correctly classifying the component failures. Numbers above the diagonal indicate the model incorrectly predicting a failure when non occured, and those below indicate incorrectly predicting a non-failure for the row indicated component failure.\n\nWhen evaluating classification models, it is convenient to reduce the results in the confusion matrix into a single performance statistic. However, depending on the problem space, it is impossible to always use the same statistic in this evaluation. Below, we calculate four such statistics.\n\n- **Accuracy**: reports how often we correctly predicted the labeled data. Unfortunatly, when there is a class imbalance (a large number of one of the labels relative to others), this measure is biased towards the largest class. In this case non-failure days.\n\nBecause of the class imbalance inherint in predictive maintenance problems, it is better to look at the remaining statistics instead. Here positive predictions indicate a failure.\n\n- **Precision**: Precision is a measure of how well the model classifies the truely positive samples. Precision depends on falsely classifying negative days as positive.\n\n- **Recall**: Recall is a measure of how well the model can find the positive samples. Recall depends on falsely classifying positive days as negative.\n\n- **F1**: F1 considers both the precision and the recall. F1 score is the harmonic average of precision and recall. An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n\nThese metrics make the most sense for binary classifiers, though they are still useful for comparision in our multiclass setting. Below we calculate these evaluation statistics for the selected classifier, and post them back to the AML workbench run time page for tracking between experiments."],"metadata":{}},{"cell_type":"code","source":["# select (prediction, true label) and compute test error\n# select (prediction, true label) and compute test error\n# True positives - diagonal failure terms \ntp = confuse['1.0'][1]+confuse['2.0'][2]+confuse['3.0'][3]+confuse['4.0'][4]\n\n# False positves - All failure terms - True positives\nfp = np.sum(np.sum(confuse[['1.0', '2.0','3.0','4.0']])) - tp\n\n# True negatives \ntn = confuse['0.0'][0]\n\n# False negatives total of non-failure column - TN\nfn = np.sum(np.sum(confuse[['0.0']])) - tn\n\n# Accuracy is diagonal/total \nacc_n = tn + tp\nacc_d = np.sum(np.sum(confuse[['0.0','1.0', '2.0','3.0','4.0']]))\nacc = acc_n/acc_d\n\n# Calculate precision and recall.\nprec = tp/(tp+fp)\nrec = tp/(tp+fn)\n\n# Print the evaluation metrics to the notebook\nprint(\"Accuracy = %g\" % acc)\nprint(\"Precision = %g\" % prec)\nprint(\"Recall = %g\" % rec )\nprint(\"F1 = %g\" % (2.0 * prec * rec/(prec + rec)))\nprint(\"\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.954493\nPrecision = 0.910948\nRecall = 0.277986\nF1 = 0.425979\n\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Remember that this is a simulated data set. We would expect a model built on real world data to behave very differently. The accuracy may still be close to one, but the precision and recall numbers would be much lower."],"metadata":{}},{"cell_type":"code","source":["predictions.toPandas().head(20)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>\n    machineID        dt_truncated  label_e  \\\n0          45 2016-01-01 12:00:00      0.0   \n1          45 2016-01-01 00:00:00      0.0   \n2          45 2015-12-31 12:00:00      0.0   \n3          45 2015-12-31 00:00:00      0.0   \n4          45 2015-12-30 12:00:00      0.0   \n5          45 2015-12-30 00:00:00      0.0   \n6          45 2015-12-29 12:00:00      0.0   \n7          45 2015-12-29 00:00:00      0.0   \n8          45 2015-12-28 12:00:00      0.0   \n9          45 2015-12-28 00:00:00      0.0   \n10         45 2015-12-27 12:00:00      0.0   \n11         45 2015-12-27 00:00:00      0.0   \n12         45 2015-12-26 12:00:00      0.0   \n13         45 2015-12-26 00:00:00      0.0   \n14         45 2015-12-25 12:00:00      0.0   \n15         45 2015-12-25 00:00:00      0.0   \n16         45 2015-12-24 12:00:00      0.0   \n17         45 2015-12-24 00:00:00      0.0   \n18         45 2015-12-23 12:00:00      0.0   \n19         45 2015-12-23 00:00:00      0.0   \n\n                                             features  indexedLabel  \\\n0   (180.192497527, 482.320763677, 123.340058678, ...           0.0   \n1   [185.441169349, 470.689865796, 115.674212621, ...           0.0   \n2   [184.01031328, 444.755575817, 103.049769247, 4...           0.0   \n3   [174.139126307, 461.528239244, 99.4343354818, ...           0.0   \n4   [169.351114918, 444.253012934, 96.7993394654, ...           0.0   \n5   [170.275399706, 463.208150561, 100.510935031, ...           0.0   \n6   [175.87402359, 443.653284824, 102.74427056, 41...           0.0   \n7   [170.26204021, 456.053290902, 99.2346402263, 3...           0.0   \n8   [169.69033341, 450.097554637, 98.3041556692, 4...           0.0   \n9   [169.857394657, 450.76328442, 100.601895961, 3...           0.0   \n10  [171.283378445, 463.236632798, 100.953781999, ...           0.0   \n11  [166.790548049, 456.412326239, 101.412157477, ...           0.0   \n12  [171.41636184, 448.722025312, 102.6334959, 41....           0.0   \n13  [173.458704761, 439.53941217, 100.886214922, 3...           0.0   \n14  [170.397340734, 423.636355064, 98.3771369872, ...           0.0   \n15  [173.591162765, 457.849396598, 99.9297326911, ...           0.0   \n16  [170.345907413, 443.917666998, 100.225179762, ...           0.0   \n17  [170.220003322, 449.074548101, 100.933044339, ...           0.0   \n18  [176.348007602, 462.315166576, 101.185218034, ...           0.0   \n19  [172.05879022, 461.15781296, 99.5618742677, 39...           0.0   \n\n                                      indexedFeatures  \\\n0   (180.192497527, 482.320763677, 123.340058678, ...   \n1   [185.441169349, 470.689865796, 115.674212621, ...   \n2   [184.01031328, 444.755575817, 103.049769247, 4...   \n3   [174.139126307, 461.528239244, 99.4343354818, ...   \n4   [169.351114918, 444.253012934, 96.7993394654, ...   \n5   [170.275399706, 463.208150561, 100.510935031, ...   \n6   [175.87402359, 443.653284824, 102.74427056, 41...   \n7   [170.26204021, 456.053290902, 99.2346402263, 3...   \n8   [169.69033341, 450.097554637, 98.3041556692, 4...   \n9   [169.857394657, 450.76328442, 100.601895961, 3...   \n10  [171.283378445, 463.236632798, 100.953781999, ...   \n11  [166.790548049, 456.412326239, 101.412157477, ...   \n12  [171.41636184, 448.722025312, 102.6334959, 41....   \n13  [173.458704761, 439.53941217, 100.886214922, 3...   \n14  [170.397340734, 423.636355064, 98.3771369872, ...   \n15  [173.591162765, 457.849396598, 99.9297326911, ...   \n16  [170.345907413, 443.917666998, 100.225179762, ...   \n17  [170.220003322, 449.074548101, 100.933044339, ...   \n18  [176.348007602, 462.315166576, 101.185218034, ...   \n19  [172.05879022, 461.15781296, 99.5618742677, 39...   \n\n                                        rawPrediction  \\\n0   [118.468664772, 6.44705444895, 51.6739844397, ...   \n1   [114.150406499, 0.57876601709, 38.2768926751, ...   \n2   [164.331958602, 1.92244196413, 31.6043665876, ...   \n3   [193.149879182, 2.07013403638, 1.54777164981, ...   \n4   [193.34560125, 1.99188040569, 1.53704873283, 2...   \n5   [193.258567576, 2.04464908749, 1.54660480101, ...   \n6   [193.011134915, 2.10836157478, 1.7682493109, 2...   \n7   [193.2681707, 1.9961731337, 1.52235725061, 2.4...   \n8   [193.355092548, 2.02233668992, 1.50700298054, ...   \n9   [193.16458824, 2.06308580599, 1.53760031726, 2...   \n10  [193.293359058, 2.04948175823, 1.50665235435, ...   \n11  [193.378110574, 1.99992939314, 1.4992679544, 2...   \n12  [193.320518503, 2.04665135767, 1.50118880604, ...   \n13  [193.040955774, 2.21847772525, 1.57686803635, ...   \n14  [167.475217592, 27.2534193674, 1.72503263342, ...   \n15  [193.249974337, 2.05975537386, 1.53170725112, ...   \n16  [192.995813015, 2.06923226137, 1.76253854455, ...   \n17  [193.26007199, 2.01563568305, 1.5681243344, 2....   \n18  [193.103288304, 2.09435883478, 1.67726162075, ...   \n19  [193.199194173, 2.02172416031, 1.64423192428, ...   \n\n                                          probability  prediction  \n0   [0.592343323862, 0.0322352722447, 0.2583699221...         0.0  \n1   [0.570752032495, 0.00289383008545, 0.191384463...         0.0  \n2   [0.821659793012, 0.00961220982066, 0.158021832...         0.0  \n3   [0.965749395909, 0.0103506701819, 0.0077388582...         0.0  \n4   [0.966728006251, 0.00995940202847, 0.007685243...         0.0  \n5   [0.966292837878, 0.0102232454375, 0.0077330240...         0.0  \n6   [0.965055674577, 0.0105418078739, 0.0088412465...         0.0  \n7   [0.9663408535, 0.00998086566848, 0.00761178625...         0.0  \n8   [0.966775462741, 0.0101116834496, 0.0075350149...         0.0  \n9   [0.9658229412, 0.0103154290299, 0.007688001586...         0.0  \n10  [0.966466795288, 0.0102474087912, 0.0075332617...         0.0  \n11  [0.966890552872, 0.0099996469657, 0.0074963397...         0.0  \n12  [0.966602592513, 0.0102332567883, 0.0075059440...         0.0  \n13  [0.965204778868, 0.0110923886263, 0.0078843401...         0.0  \n14  [0.837376087961, 0.136267096837, 0.00862516316...         0.0  \n15  [0.966249871683, 0.0102987768693, 0.0076585362...         0.0  \n16  [0.964979065075, 0.0103461613069, 0.0088126927...         0.0  \n17  [0.966300359952, 0.0100781784152, 0.0078406216...         0.0  \n18  [0.965516441521, 0.0104717941739, 0.0083863081...         0.0  \n19  [0.965995970863, 0.0101086208016, 0.0082211596...         0.0  \n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["print(predictions.summary())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">DataFrame[summary: string, machineID: string, label_e: string, indexedLabel: string, prediction: string]\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["predictions.explain()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Physical Plan ==\n*(1) FileScan parquet default.results_output[machineID#88592L,dt_truncated#88593,label_e#88594,features#88595,indexedLabel#88596,indexedFeatures#88597,rawPrediction#88598,probability#88599,prediction#88600] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex[dbfs:/user/hive/warehouse/results_output], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;machineID:bigint,dt_truncated:timestamp,label_e:double,features:struct&lt;type:tinyint,size:i...\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["# Conclusion\n\nThis concludes this scenario. You can modify these notebooks to customize your own use case solution."],"metadata":{}}],"metadata":{"kernelspec":{"display_name":"PredictiveMaintenance dlvmjme","language":"python","name":"predictivemaintenance_dlvmjme"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.5.2","nbconvert_exporter":"python","file_extension":".py"},"name":"4_model_scoring","notebookId":1086115452232427},"nbformat":4,"nbformat_minor":0}
