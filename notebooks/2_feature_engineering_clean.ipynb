{"cells":[{"cell_type":"markdown","source":["# Step 2: Feature Engineering\n\nAccording to [Wikipedia, Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering) is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive. \n\nThis Feature engineering notebook will load the data sets created in the **Data Ingestion** notebook (`Code/1_data_ingestion.ipynb`) from an Azure storage container and combine them to create a single data set of features (variables) that can be used to infer a machines's health condition over time. The notebook steps through several feature engineering and labeling methods to create this data set for use in our predictive maintenance machine learning solution.\n\n**Note:** This notebook will take about 20-30 minutes to execute all cells, depending on the compute configuration you have setup."],"metadata":{}},{"cell_type":"code","source":["## Setup our environment by importing required libraries\nimport time\nimport os\nimport glob\n\n# Read csv file from URL directly\nimport pandas as pd\n\n# For creating some preliminary EDA plots.\n# %matplotlib inline\nimport matplotlib.pyplot as plt\nfrom ggplot import *\n\nimport datetime\nfrom pyspark.sql.functions import to_date\n\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import col, unix_timestamp, round\nfrom pyspark.sql.functions import datediff\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import DoubleType\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml.feature import StringIndexer\n\nfrom pyspark.sql import SparkSession\n\n# Time the notebook execution. \n# This will only make sense if you \"Run all cells\"\ntic = time.time()\n\nspark = SparkSession.builder.getOrCreate()\n\n# These file names detail which blob each files is stored under. \nMACH_DATA = 'machines_files'\nMAINT_DATA = 'maint_files'\nERROR_DATA = 'errors_files'\nTELEMETRY_DATA = 'telemetry_files'\nFAILURE_DATA = 'failure_files'\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["dbutils.widgets.removeAll()\ndbutils.widgets.text(\"FEATURES_TABLE\",\"training_data\")\n\ndbutils.widgets.text(\"Start_Date\", '2000-01-01')\n\ndbutils.widgets.text(\"zEnd_Date\", '2015-10-30')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["## Feature engineering \n\nOur feature engineering will combine the different data sources together to create a single data set of features (variables) that can be used to infer a machines's health condition over time. The ultimate goal is to generate a single record for each time unit within each asset. The record combines features and labels to be fed into the machine learning algorithm.\n\nPredictive maintenance take historical data, marked with a timestamp, to predict current health of a component and the probability of failure within some future window of time. These problems can be characterised as a _classification method_ involving _time series_ data. Time series, since we want to use historical observations to predict what will happen in the future. Classification, because we classify the future as having a probability of failure.\n\n### Lag features\n\nThere are many ways of creating features from the time series data. We start by dividing the duration of data collection into time units where each record belongs to a single point in time for each asset. The measurement unit for is in fact arbitrary. Time can be in seconds, minutes, hours, days, or months, or it can be measured in cycles, miles or transactions. The measurement choice is typically specific to the use case domain.\n\nAdditionally, the time unit does not have to be the same as the frequency of data collection. For example, if temperature values were being collected every 10 seconds, picking a time unit of 10 seconds for analysis may inflate the number of examples without providing any additional information if the temperature changes slowly. A better strategy may be to average the temperature over a longer time horizon which might better capture variations that contribute to the target outcome.\n\nOnce we set the frequency of observations, we want to look for trends within measures, over time, in order to predict performance degradation, which we would like to connect to how likely a component will fail. We create features for these trends within each record using time lags over previous observations to check for these performance changes. The lag window size $W$ is a hyper parameter that we can optimize. The following figures indicate a _rolling aggregate window_ strategy for averaging a measure $t_i$ over a window $W = 3$ previous observations.\n\n![Rolling windows](../images/rolling-aggregate-features.png)\n\nWe are note constrained to averages, we can roll aggregates over counts, average, the standard deviation, outliers based on standard deviations, CUSUM measures, minimum and maximum values for the window. \n\nWe could also use a tumbling window approach, if we were interested in a different time window measure than the frequncy of the observations. For example, we might have obersvations evert 6 or 12 hours, but want to create features aligned on a day or week basis.  \n![Tumbling windows](../images/tumbling-aggregate-features.png)\n\nIn the following sections, we will build our features using only a rolling strategy to demonstrate the process. We align our data, and then build features along those normalized observations times. We start with the telemetry data."],"metadata":{}},{"cell_type":"markdown","source":["## Telemetry features\n\nBecause the telemetry data set is the largest time series data we have, we start feature engineering here. The telemetry data has 8761000 hourly observations for out 1000 machines. We can improve the model performance by aligning our data by aggregating average sensor measures on a tumbling 12 hour window. In this case we replace the raw data with the tumbling window data, reducing the sensor data to 731000 observations. This will directly reduce the computaton time required to do the feature engineering, labeling and modeling required for our solution.    \n\nOnce we have the reduced data, we set up our lag features by compute rolling aggregate measures such as mean, standard deviation, minimum, maximum, etc. to represent the short term history of the telemetry over time. \n\nThe following code blocks alignes the data on 12 hour observations and calculates a rolling mean and standard deviation of the telemetry data over the last 12, 24 and 36 hour lags."],"metadata":{}},{"cell_type":"code","source":["qryStr = \"SELECT * FROM \"+ TELEMETRY_DATA + \" WHERE datetime <= '\" + dbutils.widgets.get(\"zEnd_Date\") + \"' AND datetime > '\" + dbutils.widgets.get(\"Start_Date\") + \"'\"\nprint(qryStr)\ntelemetry = spark.sql(qryStr)\n\n# rolling mean and standard deviation\n# Temporary storage for rolling means\ntel_mean = telemetry\n\n# Which features are we interested in telemetry data set\nrolling_features = ['volt','rotate', 'pressure', 'vibration']\n      \n# n hours = n * 3600 seconds  \ntime_val = 12 * 3600\n\n# Choose the time_val hour timestamps to align the data\n# dt_truncated looks at the column named \"datetime\" in the current data set.\n# remember that Spark is lazy... this doesn't execute until it is in a withColumn statement.\ndt_truncated = ((round(unix_timestamp(col(\"datetime\")) / time_val) * time_val).cast(\"timestamp\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">SELECT * FROM telemetry_files WHERE datetime &lt;= &apos;2018-10-30&apos; AND datetime &gt; &apos;2015-11-15&apos;\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# We choose windows for our rolling windows 12hrs, 24 hrs and 36 hrs\nlags = [12, 24, 36]\n\n# align the data\nfor lag_n in lags:\n    wSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-lag_n, 0)\n    for col_name in rolling_features:\n        tel_mean = tel_mean.withColumn(col_name+'_rollingmean_'+str(lag_n), \n                                       F.avg(col(col_name)).over(wSpec))\n        tel_mean = tel_mean.withColumn(col_name+'_rollingstd_'+str(lag_n), \n                                       F.stddev(col(col_name)).over(wSpec))\n\n# Calculate lag values...\ntelemetry_feat = (tel_mean.withColumn(\"dt_truncated\", dt_truncated)\n                  .drop('volt', 'rotate', 'pressure', 'vibration')\n                  .fillna(0)\n                  .groupBy(\"machineID\",\"dt_truncated\")\n                  .agg(F.mean('volt_rollingmean_12').alias('volt_rollingmean_12'),\n                       F.mean('rotate_rollingmean_12').alias('rotate_rollingmean_12'), \n                       F.mean('pressure_rollingmean_12').alias('pressure_rollingmean_12'), \n                       F.mean('vibration_rollingmean_12').alias('vibration_rollingmean_12'), \n                       F.mean('volt_rollingmean_24').alias('volt_rollingmean_24'),\n                       F.mean('rotate_rollingmean_24').alias('rotate_rollingmean_24'), \n                       F.mean('pressure_rollingmean_24').alias('pressure_rollingmean_24'), \n                       F.mean('vibration_rollingmean_24').alias('vibration_rollingmean_24'),\n                       F.mean('volt_rollingmean_36').alias('volt_rollingmean_36'),\n                       F.mean('vibration_rollingmean_36').alias('vibration_rollingmean_36'),\n                       F.mean('rotate_rollingmean_36').alias('rotate_rollingmean_36'), \n                       F.mean('pressure_rollingmean_36').alias('pressure_rollingmean_36'), \n                       F.stddev('volt_rollingstd_12').alias('volt_rollingstd_12'),\n                       F.stddev('rotate_rollingstd_12').alias('rotate_rollingstd_12'), \n                       F.stddev('pressure_rollingstd_12').alias('pressure_rollingstd_12'), \n                       F.stddev('vibration_rollingstd_12').alias('vibration_rollingstd_12'), \n                       F.stddev('volt_rollingstd_24').alias('volt_rollingstd_24'),\n                       F.stddev('rotate_rollingstd_24').alias('rotate_rollingstd_24'), \n                       F.stddev('pressure_rollingstd_24').alias('pressure_rollingstd_24'), \n                       F.stddev('vibration_rollingstd_24').alias('vibration_rollingstd_24'),\n                       F.stddev('volt_rollingstd_36').alias('volt_rollingstd_36'),\n                       F.stddev('rotate_rollingstd_36').alias('rotate_rollingstd_36'), \n                       F.stddev('pressure_rollingstd_36').alias('pressure_rollingstd_36'), \n                       F.stddev('vibration_rollingstd_36').alias('vibration_rollingstd_36'), ))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">96000\n<span class=\"ansired\">Out[</span><span class=\"ansired\">24</span><span class=\"ansired\">]: </span>\n   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n0          1 2015-12-17 00:00:00           169.167041             455.734514   \n1          1 2015-12-11 12:00:00           173.352547             448.775731   \n2          1 2015-12-19 12:00:00           164.843162             429.836585   \n3          1 2015-12-13 00:00:00           177.011104             452.701917   \n4          1 2015-12-18 12:00:00           171.289157             439.045915   \n5          1 2015-11-16 00:00:00           186.502218             459.974033   \n6          1 2015-11-24 12:00:00           169.476617             442.790670   \n7          1 2015-12-26 00:00:00           166.870879             448.473171   \n8          1 2015-12-19 00:00:00           167.576134             450.898107   \n9          1 2015-12-25 00:00:00           169.133148             429.630218   \n\n   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n0                98.842483                 39.104152           171.370731   \n1               101.412437                 39.027765           171.292002   \n2               101.942104                 39.061395           166.209648   \n3               121.725091                 39.525528           175.988290   \n4               101.394671                 40.717717           169.596060   \n5               100.911766                 38.742478           187.954851   \n6                97.963717                 39.549298           169.883607   \n7               101.023943                 39.137202           167.624520   \n8               101.048209                 40.104845           169.432646   \n9               100.524888                 38.171276           173.183556   \n\n   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n0             452.306194                98.278780                 42.471398   \n1             444.774327               101.879997                 39.588702   \n2             440.367346               101.495157                 39.583120   \n3             442.301466               121.719897                 39.458416   \n4             451.309115               103.295375                 41.442660   \n5             459.758182               100.385110                 39.830120   \n6             449.572184                98.037667                 39.347424   \n7             443.226707               100.029503                 39.462094   \n8             444.972011               101.221440                 40.411281   \n9             433.920872               100.032742                 38.363267   \n\n            ...             pressure_rollingstd_12  vibration_rollingstd_12  \\\n0           ...                           1.031176                 0.801300   \n1           ...                           1.520909                 0.524005   \n2           ...                           0.649582                 0.714251   \n3           ...                           1.477395                 0.144161   \n4           ...                           0.792657                 0.987661   \n5           ...                           0.467253                 0.383934   \n6           ...                           1.440137                 0.411173   \n7           ...                           0.381593                 0.986539   \n8           ...                           1.285195                 0.433688   \n9           ...                           0.886448                 0.860949   \n\n   volt_rollingstd_24  rotate_rollingstd_24  pressure_rollingstd_24  \\\n0            0.874356              2.523363                1.116471   \n1            0.491613              2.037811                0.483161   \n2            0.474559              2.328047                0.320191   \n3            0.244662              3.673056                0.299022   \n4            0.615732              1.524631                0.774910   \n5            0.587934              1.874871                0.371892   \n6            0.750819              1.866814                0.893959   \n7            0.522484              6.129426                0.356957   \n8            1.842796              1.817469                0.977031   \n9            0.703096              2.584679                0.746109   \n\n   vibration_rollingstd_24  volt_rollingstd_36  rotate_rollingstd_36  \\\n0                 0.800095            0.505470              2.272075   \n1                 0.292491            0.961163              2.095341   \n2                 0.204196            0.249691              1.100880   \n3                 0.152636            0.204111              1.320518   \n4                 0.277231            0.849947              0.893086   \n5                 0.265864            0.560079              1.651064   \n6                 0.230247            0.220048              2.173188   \n7                 0.276796            0.440065              1.785638   \n8                 0.549482            1.176273              1.265127   \n9                 0.220573            0.813799              2.336047   \n\n   pressure_rollingstd_36  vibration_rollingstd_36  \n0                0.260917                 0.302917  \n1                0.306276                 0.286464  \n2                0.402517                 0.314121  \n3                1.432209                 0.123397  \n4                0.371480                 0.216065  \n5                0.210456                 0.170387  \n6                0.352328                 0.124771  \n7                0.148917                 0.291837  \n8                0.342829                 0.217780  \n9                0.322749                 0.225834  \n\n[10 rows x 26 columns]\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## Errors features\n\nLike telemetry data, errors come with timestamps. An important difference is that the error IDs are categorical values and should not be averaged over time intervals like the telemetry measurements. Instead, we count the number of errors of each type within a lag window. \n\nAgain, we align the error counts data by tumbling over the 12 hour window using a join with telemetry data."],"metadata":{}},{"cell_type":"code","source":["errors = spark.sql(\"SELECT * FROM \" + ERROR_DATA + \" WHERE datetime <= '\" + dbutils.widgets.get(\"zEnd_Date\") + \"' AND datetime > '\" + dbutils.widgets.get(\"Start_Date\") + \"'\")\n\n# create a column for each errorID \nerror_ind = (errors.groupBy(\"machineID\",\"datetime\",\"errorID\").pivot('errorID')\n             .agg(F.count('machineID').alias('dummy')).drop('errorID').fillna(0)\n             .groupBy(\"machineID\",\"datetime\")\n             .agg(F.sum('error1').alias('error1sum'), \n                  F.sum('error2').alias('error2sum'), \n                  F.sum('error3').alias('error3sum'), \n                  F.sum('error4').alias('error4sum'), \n                  F.sum('error5').alias('error5sum')))\n\n# join the telemetry data with errors\nerror_count = (telemetry.join(error_ind, \n                              ((telemetry['machineID'] == error_ind['machineID']) \n                               & (telemetry['datetime'] == error_ind['datetime'])), \"left\")\n               .drop('volt', 'rotate', 'pressure', 'vibration')\n               .drop(error_ind.machineID).drop(error_ind.datetime)\n               .fillna(0))\n\nerror_features = ['error1sum','error2sum', 'error3sum', 'error4sum', 'error5sum']\n\nwSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-24, 0)\nfor col_name in error_features:\n    # We're only interested in the erros in the previous 24 hours.\n    error_count = error_count.withColumn(col_name+'_rollingmean_24', \n                                         F.avg(col(col_name)).over(wSpec))\n\nerror_feat = (error_count.withColumn(\"dt_truncated\", dt_truncated)\n              .drop('error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum').fillna(0)\n              .groupBy(\"machineID\",\"dt_truncated\")\n              .agg(F.mean('error1sum_rollingmean_24').alias('error1sum_rollingmean_24'), \n                   F.mean('error2sum_rollingmean_24').alias('error2sum_rollingmean_24'), \n                   F.mean('error3sum_rollingmean_24').alias('error3sum_rollingmean_24'), \n                   F.mean('error4sum_rollingmean_24').alias('error4sum_rollingmean_24'), \n                   F.mean('error5sum_rollingmean_24').alias('error5sum_rollingmean_24')))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">96000\n<span class=\"ansired\">Out[</span><span class=\"ansired\">25</span><span class=\"ansired\">]: </span>\n   machineID        dt_truncated  error1sum_rollingmean_24  \\\n0        474 2015-12-06 12:00:00                       0.0   \n1        222 2015-11-28 00:00:00                       0.0   \n2        270 2015-12-13 12:00:00                       0.0   \n3        293 2015-11-18 00:00:00                       0.0   \n4        270 2015-12-18 00:00:00                       0.0   \n5        551 2015-11-21 12:00:00                       0.0   \n6        830 2015-11-18 12:00:00                       0.0   \n7        406 2015-12-05 12:00:00                       0.0   \n8        638 2015-12-08 00:00:00                       0.0   \n9        876 2015-12-12 12:00:00                       0.0   \n\n   error2sum_rollingmean_24  error3sum_rollingmean_24  \\\n0                       0.0                       0.0   \n1                       0.0                       0.0   \n2                       0.0                       0.0   \n3                       0.0                       0.0   \n4                       0.0                       0.0   \n5                       0.0                       0.0   \n6                       0.0                       0.0   \n7                       0.0                       0.0   \n8                       0.0                       0.0   \n9                       0.0                       0.0   \n\n   error4sum_rollingmean_24  error5sum_rollingmean_24  \n0                       0.0                       0.0  \n1                       0.0                       0.0  \n2                       0.0                       0.0  \n3                       0.0                       0.0  \n4                       0.0                       0.0  \n5                       0.0                       0.0  \n6                       0.0                       0.0  \n7                       0.0                       0.0  \n8                       0.0                       0.0  \n9                       0.0                       0.0  \n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["## Days since last replacement from maintenance \n\nA crucial data set in this example is the use of maintenance records, which contain the information regarding component replacement. Possible features from this data set can be the number of replacements of each component over time or to calculate how long it has been since a component has been replaced. Replacement time is expected to correlate better with component failures since the longer a component is used, the more degradation would be expected.\n\nAs a side note, creating lagging features from maintenance data is not straight forward. This type of ad-hoc feature engineering is very common in predictive maintenance as domain knowledge plays a crucial role in understanding the predictors of a failure problem. In the following code blocks, the days since last component replacement are calculated for each component from the maintenance data. We start by counting the component replacements for the set of machines."],"metadata":{}},{"cell_type":"code","source":["maint = spark.sql(\"SELECT * FROM \" + MAINT_DATA + \" WHERE datetime <= '\" + dbutils.widgets.get(\"zEnd_Date\") + \"' AND datetime > '\" + dbutils.widgets.get(\"Start_Date\") + \"'\")\n\n# create a column for each component replacement\nmaint_replace = (maint.groupBy(\"machineID\",\"datetime\",\"comp\").pivot('comp')\n                 .agg(F.count('machineID').alias('dummy')).fillna(0)\n                 .groupBy(\"machineID\",\"datetime\")\n                 .agg(F.sum('comp1').alias('comp1sum'), \n                      F.sum('comp2').alias('comp2sum'), \n                      F.sum('comp3').alias('comp3sum'),\n                      F.sum('comp4').alias('comp4sum')))\n\nmaint_replace = maint_replace.withColumnRenamed('datetime','datetime_maint')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2861\n<span class=\"ansired\">Out[</span><span class=\"ansired\">26</span><span class=\"ansired\">]: </span>\n   machineID       datetime_maint  comp1sum  comp2sum  comp3sum  comp4sum\n0        548  2015-12-07 06:00:00         0         0         1         0\n1        827  2015-12-28 06:00:00         0         1         0         0\n2        681  2015-11-25 06:00:00         0         1         0         0\n3        816  2015-11-17 06:00:00         0         1         0         0\n4        322  2015-11-27 06:00:00         1         0         1         0\n5        382  2015-11-22 06:00:00         1         0         1         0\n6        435  2015-11-30 06:00:00         1         0         1         0\n7        616  2015-12-19 06:00:00         0         0         1         0\n8        191  2015-12-28 06:00:00         1         0         0         0\n9        890  2015-12-30 06:00:00         1         0         0         0\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["Replacement features are then created by tracking the number of days between each component replacement. We'll repeat these calculations for each of the four components and join them together into a maintenance feature table.\n\nFirst component number 1 (`comp1`):"],"metadata":{}},{"cell_type":"code","source":["# We want to align the component information on telemetry features timestamps.\ntelemetry_times = (telemetry_feat.select(telemetry_feat.machineID, telemetry_feat.dt_truncated)\n                   .withColumnRenamed('dt_truncated','datetime_tel'))\n\n# Grab component 1 records\nmaint_comp1 = (maint_replace.where(col(\"comp1sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n               .drop('comp2sum', 'comp3sum', 'comp4sum'))\n\n# Within each machine, get the last replacement date for each timepoint\nmaint_tel_comp1 = (telemetry_times.join(maint_comp1, \n                                        ((telemetry_times ['machineID']== maint_comp1['machineID']) \n                                         & (telemetry_times ['datetime_tel'] > maint_comp1['datetime_maint']) \n                                         & ( maint_comp1['comp1sum'] == '1')))\n                   .drop(maint_comp1.machineID))\n\n# Calculate the number of days between replacements\ncomp1 = (maint_tel_comp1.withColumn(\"sincelastcomp1\", \n                                    datediff(maint_tel_comp1.datetime_tel, maint_tel_comp1.datetime_maint))\n         .drop(maint_tel_comp1.datetime_maint).drop(maint_tel_comp1.comp1sum))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">46531\n<span class=\"ansired\">Out[</span><span class=\"ansired\">27</span><span class=\"ansired\">]: </span>\nEmpty DataFrame\nColumns: [machineID, datetime_tel, sincelastcomp1]\nIndex: []\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["Then component 2 (`comp2`):"],"metadata":{}},{"cell_type":"code","source":["# Grab component 2 records\nmaint_comp2 = (maint_replace.where(col(\"comp2sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n               .drop('comp1sum', 'comp3sum', 'comp4sum'))\n\n# Within each machine, get the last replacement date for each timepoint\nmaint_tel_comp2 = (telemetry_times.join(maint_comp2, \n                                        ((telemetry_times ['machineID']== maint_comp2['machineID']) \n                                         & (telemetry_times ['datetime_tel'] > maint_comp2['datetime_maint']) \n                                         & ( maint_comp2['comp2sum'] == '1')))\n                   .drop(maint_comp2.machineID))\n\n# Calculate the number of days between replacements\ncomp2 = (maint_tel_comp2.withColumn(\"sincelastcomp2\", \n                                    datediff(maint_tel_comp2.datetime_tel, maint_tel_comp2.datetime_maint))\n         .drop(maint_tel_comp2.datetime_maint).drop(maint_tel_comp2.comp2sum))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">44748\n<span class=\"ansired\">Out[</span><span class=\"ansired\">28</span><span class=\"ansired\">]: </span>\n   machineID        datetime_tel  sincelastcomp2\n0        625 2015-11-19 12:00:00               0\n1        625 2015-11-20 00:00:00               1\n2        625 2015-11-20 12:00:00               1\n3        625 2015-11-21 00:00:00               2\n4        625 2015-11-21 12:00:00               2\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Then component 3 (`comp3`):"],"metadata":{}},{"cell_type":"code","source":["# Grab component 3 records\nmaint_comp3 = (maint_replace.where(col(\"comp3sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n               .drop('comp1sum', 'comp2sum', 'comp4sum'))\n\n# Within each machine, get the last replacement date for each timepoint\nmaint_tel_comp3 = (telemetry_times.join(maint_comp3, ((telemetry_times ['machineID']==maint_comp3['machineID']) \n                                                      & (telemetry_times ['datetime_tel'] > maint_comp3['datetime_maint']) \n                                                      & ( maint_comp3['comp3sum'] == '1')))\n                   .drop(maint_comp3.machineID))\n\n# Calculate the number of days between replacements\ncomp3 = (maint_tel_comp3.withColumn(\"sincelastcomp3\", \n                                    datediff(maint_tel_comp3.datetime_tel, maint_tel_comp3.datetime_maint))\n         .drop(maint_tel_comp3.datetime_maint).drop(maint_tel_comp3.comp3sum))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">47183\n<span class=\"ansired\">Out[</span><span class=\"ansired\">29</span><span class=\"ansired\">]: </span>\nEmpty DataFrame\nColumns: [machineID, datetime_tel, sincelastcomp3]\nIndex: []\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["and component 4 (`comp4`):"],"metadata":{}},{"cell_type":"code","source":["# Grab component 4 records\nmaint_comp4 = (maint_replace.where(col(\"comp4sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n               .drop('comp1sum', 'comp2sum', 'comp3sum'))\n\n# Within each machine, get the last replacement date for each timepoint\nmaint_tel_comp4 = telemetry_times.join(maint_comp4, ((telemetry_times['machineID']==maint_comp4['machineID']) \n                                                     & (telemetry_times['datetime_tel'] > maint_comp4['datetime_maint']) \n                                                     & (maint_comp4['comp4sum'] == '1'))).drop(maint_comp4.machineID)\n\n# Calculate the number of days between replacements\ncomp4 = (maint_tel_comp4.withColumn(\"sincelastcomp4\", \n                                    datediff(maint_tel_comp4.datetime_tel, maint_tel_comp4.datetime_maint))\n         .drop(maint_tel_comp4.datetime_maint).drop(maint_tel_comp4.comp4sum))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">43187\n<span class=\"ansired\">Out[</span><span class=\"ansired\">30</span><span class=\"ansired\">]: </span>\n   machineID        datetime_tel  sincelastcomp4\n0        625 2015-12-04 12:00:00               0\n1        625 2015-12-05 00:00:00               1\n2        625 2015-12-05 12:00:00               1\n3        625 2015-12-06 00:00:00               2\n4        625 2015-12-06 12:00:00               2\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["Now, we join the four component replacement tables together. Once joined, align the data by tumbling the average across 12 hour observation windows."],"metadata":{}},{"cell_type":"code","source":["# Join component 3 and 4\ncomp3_4 = (comp3.join(comp4, ((comp3['machineID'] == comp4['machineID']) \n                              & (comp3['datetime_tel'] == comp4['datetime_tel'])), \"left\")\n           .drop(comp4.machineID).drop(comp4.datetime_tel))\n\n# Join component 2 to 3 and 4\ncomp2_3_4 = (comp2.join(comp3_4, ((comp2['machineID'] == comp3_4['machineID']) \n                                  & (comp2['datetime_tel'] == comp3_4['datetime_tel'])), \"left\")\n             .drop(comp3_4.machineID).drop(comp3_4.datetime_tel))\n\n# Join component 1 to 2, 3 and 4\ncomps_feat = (comp1.join(comp2_3_4, ((comp1['machineID'] == comp2_3_4['machineID']) \n                                      & (comp1['datetime_tel'] == comp2_3_4['datetime_tel'])), \"left\")\n               .drop(comp2_3_4.machineID).drop(comp2_3_4.datetime_tel)\n               .groupBy(\"machineID\", \"datetime_tel\")\n               .agg(F.max('sincelastcomp1').alias('sincelastcomp1'), \n                    F.max('sincelastcomp2').alias('sincelastcomp2'), \n                    F.max('sincelastcomp3').alias('sincelastcomp3'), \n                    F.max('sincelastcomp4').alias('sincelastcomp4'))\n               .fillna(0))\n\n# Choose the time_val hour timestamps to align the data\ndt_truncated = ((round(unix_timestamp(col(\"datetime_tel\")) / time_val) * time_val).cast(\"timestamp\"))\n\n# Collect data\nmaint_feat = (comps_feat.withColumn(\"dt_truncated\", dt_truncated)\n              .groupBy(\"machineID\",\"dt_truncated\")\n              .agg(F.mean('sincelastcomp1').alias('comp1sum'), \n                   F.mean('sincelastcomp2').alias('comp2sum'), \n                   F.mean('sincelastcomp3').alias('comp3sum'), \n                   F.mean('sincelastcomp4').alias('comp4sum')))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">16839\n<span class=\"ansired\">Out[</span><span class=\"ansired\">31</span><span class=\"ansired\">]: </span>\n   machineID        dt_truncated  comp1sum  comp2sum  comp3sum  comp4sum\n0         10 2015-12-13 00:00:00      17.0       2.0       0.0       0.0\n1         31 2015-12-24 00:00:00      12.0      12.0       0.0       0.0\n2         32 2015-12-18 12:00:00      19.0      19.0       0.0       0.0\n3         65 2015-12-30 12:00:00       0.0      45.0       0.0      30.0\n4         78 2015-12-24 00:00:00       4.0      34.0       0.0       0.0\n5         82 2015-12-21 12:00:00      19.0       4.0       0.0       0.0\n6         88 2016-01-01 00:00:00      39.0      24.0       0.0       0.0\n7         91 2015-12-09 00:00:00      20.0       5.0       0.0       0.0\n8        122 2015-12-18 00:00:00       9.0       9.0       0.0       0.0\n9        123 2015-12-28 12:00:00      19.0       4.0      19.0       4.0\n</div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["## Machine features\n\nThe machine features capture specifics of the individuals. These can be used without further modification since it include descriptive information about the type of each machine and its age (number of years in service). If the age information had been recorded as a \"first use date\" for each machine, a transformation would have been necessary to turn those into a numeric values indicating the years in service.\n\nWe do need to create a set of dummy features, a set of boolean variables, to indicate the model of the machine. This can either be done manually, or using a _one-hot encoding_ step. We use the one-hot encoding for demonstration purposes."],"metadata":{}},{"cell_type":"code","source":["machines = spark.sql(\"SELECT * FROM \" + MACH_DATA)\n\n# one hot encoding of the variable model, basically creates a set of dummy boolean variables\ncatVarNames = ['model']  \nsIndexers = [StringIndexer(inputCol=x, outputCol=x + '_indexed') for x in catVarNames]\nmachines_cat = Pipeline(stages=sIndexers).fit(machines).transform(machines)\n\n# one-hot encode\nohEncoders = [OneHotEncoder(inputCol=x + '_indexed', outputCol=x + '_encoded')\n              for x in catVarNames]\n\nohPipelineModel = Pipeline(stages=ohEncoders).fit(machines_cat)\nmachines_cat = ohPipelineModel.transform(machines_cat)\n\ndrop_list = [col_n for col_n in machines_cat.columns if 'indexed' in col_n]\n\nmachines_feat = machines_cat.select([column for column in machines_cat.columns if column not in drop_list])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1000\n<span class=\"ansired\">Out[</span><span class=\"ansired\">32</span><span class=\"ansired\">]: </span>\n   machineID   model  age    model_encoded\n0          1  model2   18  (0.0, 0.0, 1.0)\n1          2  model4    7  (0.0, 1.0, 0.0)\n2          3  model3    8  (1.0, 0.0, 0.0)\n3          4  model3    7  (1.0, 0.0, 0.0)\n4          5  model2    2  (0.0, 0.0, 1.0)\n5          6  model3    7  (1.0, 0.0, 0.0)\n6          7  model4   20  (0.0, 1.0, 0.0)\n7          8  model3   16  (1.0, 0.0, 0.0)\n8          9  model1    7  (0.0, 0.0, 0.0)\n9         10  model1   10  (0.0, 0.0, 0.0)\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["## Merging feature data\n\nNext, we merge the telemetry, maintenance, machine and error feature data sets into a large feature data set. Since most of the data has already been aligned on the 12 hour observation period, we can merge with a simple join strategy."],"metadata":{}},{"cell_type":"code","source":["# join error features with component maintenance features\nerror_maint = (error_feat.join(maint_feat, \n                               ((error_feat['machineID'] == maint_feat['machineID']) \n                                & (error_feat['dt_truncated'] == maint_feat['dt_truncated'])), \"left\")\n               .drop(maint_feat.machineID).drop(maint_feat.dt_truncated))\n\n# now join that with machines features\nerror_maint_feat = (error_maint.join(machines_feat, \n                                     ((error_maint['machineID'] == machines_feat['machineID'])), \"left\")\n                    .drop(machines_feat.machineID))\n\n# Clean up some unecessary columns\nerror_maint_feat = error_maint_feat.select([c for c in error_maint_feat.columns if c not in \n                                            {'error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum'}])\n\n# join telemetry with error/maint/machine features to create final feature matrix\nfinal_feat = (telemetry_feat.join(error_maint_feat, \n                                  ((telemetry_feat['machineID'] == error_maint_feat['machineID']) \n                                   & (telemetry_feat['dt_truncated'] == error_maint_feat['dt_truncated'])), \"left\")\n              .drop(error_maint_feat.machineID).drop(error_maint_feat.dt_truncated))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">96000\n<span class=\"ansired\">Out[</span><span class=\"ansired\">33</span><span class=\"ansired\">]: </span>\n   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n0        625 2015-11-15 00:00:00           173.313636             413.589424   \n1        625 2015-11-15 12:00:00           168.076272             436.370234   \n2        625 2015-11-16 00:00:00           171.461903             449.926914   \n3        625 2015-11-16 12:00:00           174.404799             452.912564   \n4        625 2015-11-17 00:00:00           174.549991             457.998127   \n5        625 2015-11-17 12:00:00           171.071309             410.983262   \n6        625 2015-11-18 00:00:00           168.761894             375.872670   \n7        625 2015-11-18 12:00:00           172.540384             371.445588   \n8        625 2015-11-19 00:00:00           169.663562             363.563467   \n9        625 2015-11-19 12:00:00           167.786621             387.491819   \n\n   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n0               103.414876                 44.834407           173.313636   \n1                99.387554                 41.483057           168.683844   \n2               101.909371                 39.708162           169.753183   \n3                98.725683                 39.172595           172.933351   \n4               100.925576                 38.759642           174.477395   \n5               103.166252                 40.762635           172.810650   \n6               101.236198                 42.253776           169.916601   \n7                96.564944                 41.926805           170.651139   \n8                98.350601                 41.254793           171.101973   \n9                98.829877                 40.253947           168.725091   \n\n   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n0             413.589424               103.414876                 44.834407   \n1             434.719172                99.938255                 41.765257   \n2             443.543654               100.693021                 40.545098   \n3             451.419739               100.317527                 39.440378   \n4             455.455345                99.825630                 38.966118   \n5             434.490695               102.045914                 39.761138   \n6             393.427966               102.201225                 41.508206   \n7             373.659129                98.900571                 42.090290   \n8             367.504528                97.457773                 41.590799   \n9             375.527643                98.590239                 40.754370   \n\n        ...         error3sum_rollingmean_24  error4sum_rollingmean_24  \\\n0       ...                         0.000000                       0.0   \n1       ...                         0.000000                       0.0   \n2       ...                         0.000000                       0.0   \n3       ...                         0.000000                       0.0   \n4       ...                         0.000000                       0.0   \n5       ...                         0.000000                       0.0   \n6       ...                         0.000000                       0.0   \n7       ...                         0.041667                       0.0   \n8       ...                         0.041667                       0.0   \n9       ...                         0.000000                       0.0   \n\n   error5sum_rollingmean_24  comp1sum  comp2sum  comp3sum  comp4sum   model  \\\n0                       0.0      None      None      None      None  model3   \n1                       0.0      None      None      None      None  model3   \n2                       0.0      None      None      None      None  model3   \n3                       0.0      None      None      None      None  model3   \n4                       0.0      None      None      None      None  model3   \n5                       0.0      None      None      None      None  model3   \n6                       0.0      None      None      None      None  model3   \n7                       0.0      None      None      None      None  model3   \n8                       0.0      None      None      None      None  model3   \n9                       0.0      None      None      None      None  model3   \n\n   age    model_encoded  \n0   13  (1.0, 0.0, 0.0)  \n1   13  (1.0, 0.0, 0.0)  \n2   13  (1.0, 0.0, 0.0)  \n3   13  (1.0, 0.0, 0.0)  \n4   13  (1.0, 0.0, 0.0)  \n5   13  (1.0, 0.0, 0.0)  \n6   13  (1.0, 0.0, 0.0)  \n7   13  (1.0, 0.0, 0.0)  \n8   13  (1.0, 0.0, 0.0)  \n9   13  (1.0, 0.0, 0.0)  \n\n[10 rows x 38 columns]\n</div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["# Label construction\n\nPredictive maintenance is supervised learning. To train a model to predict failures requires examples of failures, and the time series of observations leading up to those failures. Additionally, the model needs examples of periods of healthy operation in order to discern the difference between the two states. The classification between these states is typically a boolean label (healthy vs failed).\n\nOnce we have the healthy vs. failure states, the predictive maintenance approach is only useful if the method will give some advanced warning of an impending failure. To accomplish this _prior warning_ criteria, we slightly modify the label definition from a _failure event_ which occurs at a specific moment in time, to a longer window of _failure event occurs within this window_. The window length is defined by the business criteria. Is knowing a failure will occur within 12 hours, enough time to prevent the failure from happening? Is 24 hours, or 2 weeks? The ability of the model to accurately predict an impending failure is dependent sizing this window. If the failure signal is short, longer windows will not help, and can actually degrade, the potential performance.   \n\nTo acheive the redefinition of failure to _about to fail_, we over label failure events, labeling all observations within the failure warning window as failed. The prediction problem then becomes estimating the probability of failure within this window. \n\n![over label](../images/labelling-for-binary-classification.png)\n\nFor this example scenerio, we estimate the probability that a machine will fail in the near future due to a failure of a certain component. More specifically, the goal is to compute the probability that a machine will fail in the next 7 days due to a component failure (component 1, 2, 3, or 4). \n\nBelow, a categorical failure feature is created to serve as the label. All records within a 24 hour window before a failure of component 1 have failure=\"comp1\", and so on for components 2, 3, and 4; all records not within 7 days of a component failure have failure=\"none\".\n\nThe first step is to alighn the failure data to the feature observation time points (every 12 hours)."],"metadata":{}},{"cell_type":"code","source":["failures = spark.sql(\"SELECT * FROM \" + FAILURE_DATA + \" WHERE datetime <= '\" + dbutils.widgets.get(\"zEnd_Date\") + \"' AND datetime > '\" + dbutils.widgets.get(\"Start_Date\") + \"'\")\n\n# We need to redefine dt_truncated to align with the failures table\ndt_truncated = ((round(unix_timestamp(col(\"datetime\")) / time_val) * time_val).cast(\"timestamp\"))\n\nfail_diff = (failures.withColumn(\"dt_truncated\", dt_truncated)\n             .drop(failures.datetime))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">855\n<span class=\"ansired\">Out[</span><span class=\"ansired\">34</span><span class=\"ansired\">]: </span>\n   machineID failure        dt_truncated\n0        499   comp3 2015-11-19 12:00:00\n1        499   comp2 2015-12-04 12:00:00\n2        503   comp1 2015-11-29 12:00:00\n3        504   comp2 2015-11-25 12:00:00\n4        505   comp3 2015-11-24 12:00:00\n5        506   comp2 2015-12-18 12:00:00\n6        506   comp3 2015-12-18 12:00:00\n7        507   comp2 2015-11-22 12:00:00\n8        507   comp2 2015-12-22 12:00:00\n9        508   comp2 2015-11-29 12:00:00\n</div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["Next, we convert the labels from text to numeric values. In the end, this will transform the problem from boolean of 'healthy'/'impending failure' to a multiclass 'healthy'/'component `n` impending failure'."],"metadata":{}},{"cell_type":"code","source":["# map the failure data to final feature matrix\nlabeled_features = (final_feat.join(fail_diff, \n                                    ((final_feat['machineID'] == fail_diff['machineID']) \n                                     & (final_feat['dt_truncated'] == fail_diff['dt_truncated'])), \"left\")\n                    .drop(fail_diff.machineID).drop(fail_diff.dt_truncated)\n                    .withColumn('failure', F.when(col('failure') == \"comp1\", 1.0).otherwise(col('failure')))\n                    .withColumn('failure', F.when(col('failure') == \"comp2\", 2.0).otherwise(col('failure')))\n                    .withColumn('failure', F.when(col('failure') == \"comp3\", 3.0).otherwise(col('failure')))\n                    .withColumn('failure', F.when(col('failure') == \"comp4\", 4.0).otherwise(col('failure'))))\n\nlabeled_features = (labeled_features.withColumn(\"failure\", \n                                                labeled_features.failure.cast(DoubleType()))\n                    .fillna(0))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">96045\n<span class=\"ansired\">Out[</span><span class=\"ansired\">35</span><span class=\"ansired\">]: </span>\n   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n0          1 2015-12-17 00:00:00           169.167041             455.734514   \n1          4 2015-11-15 12:00:00           166.176283             475.786402   \n2         10 2015-12-13 00:00:00           172.294493             453.327608   \n3         20 2015-11-19 12:00:00           169.430979             449.664116   \n4         21 2015-12-28 00:00:00           171.940352             434.083092   \n5         23 2015-12-22 12:00:00           167.834373             455.337218   \n6         24 2015-12-11 12:00:00           169.475632             439.917804   \n7         31 2015-12-24 00:00:00           171.212460             454.937585   \n8         32 2015-12-18 12:00:00           173.203352             420.979746   \n9         37 2015-12-01 00:00:00           172.837708             456.406460   \n\n   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n0                98.842483                 39.104152           171.370731   \n1                98.744878                 41.542195           165.931174   \n2                99.710644                 39.170496           172.974865   \n3                97.153187                 40.369704           170.018311   \n4                98.124792                 39.294411           172.441978   \n5                97.659723                 42.268168           167.897947   \n6                98.996968                 39.762002           173.557568   \n7                99.999622                 42.095909           169.460249   \n8               100.874214                 42.370792           175.264592   \n9                98.166716                 39.898668           170.614178   \n\n   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n0             452.306194                98.278780                 42.471398   \n1             480.928457                98.650952                 42.084543   \n2             443.273209                99.879658                 39.597084   \n3             445.741569                98.427073                 40.824741   \n4             436.452793                99.337400                 39.182106   \n5             460.927479                97.885637                 41.006564   \n6             447.628272                98.445987                 39.274353   \n7             455.509521                99.445650                 42.070910   \n8             439.755770               100.105743                 41.261322   \n9             455.872819               106.114435                 39.871516   \n\n    ...     error4sum_rollingmean_24  error5sum_rollingmean_24  comp1sum  \\\n0   ...                          0.0                       0.0       0.0   \n1   ...                          0.0                       0.0       0.0   \n2   ...                          0.0                       0.0      17.0   \n3   ...                          0.0                       0.0       0.0   \n4   ...                          0.0                       0.0       0.0   \n5   ...                          0.0                       0.0       0.0   \n6   ...                          0.0                       0.0       0.0   \n7   ...                          0.0                       0.0      12.0   \n8   ...                          0.0                       0.0      19.0   \n9   ...                          0.0                       0.0       0.0   \n\n   comp2sum  comp3sum  comp4sum   model  age    model_encoded  failure  \n0       0.0       0.0       0.0  model2   18  (0.0, 0.0, 1.0)      0.0  \n1       0.0       0.0       0.0  model3    7  (1.0, 0.0, 0.0)      0.0  \n2       2.0       0.0       0.0  model1   10  (0.0, 0.0, 0.0)      0.0  \n3       0.0       0.0       0.0  model2   16  (0.0, 0.0, 1.0)      0.0  \n4       0.0       0.0       0.0  model3   14  (1.0, 0.0, 0.0)      0.0  \n5       0.0       0.0       0.0  model3   17  (1.0, 0.0, 0.0)      0.0  \n6       0.0       0.0       0.0  model1   20  (0.0, 0.0, 0.0)      0.0  \n7      12.0       0.0       0.0  model3   11  (1.0, 0.0, 0.0)      0.0  \n8      19.0       0.0       0.0  model2   15  (0.0, 0.0, 1.0)      0.0  \n9       0.0       0.0       0.0  model4   16  (0.0, 1.0, 0.0)      0.0  \n\n[10 rows x 39 columns]\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["To verify we have assigned the component failure records correctly, we count the failure classes within the feature data."],"metadata":{}},{"cell_type":"markdown","source":["To now, we have labels as _failure events_. To convert to _impending failure_, we over label over the previous 7 days as _failed_."],"metadata":{}},{"cell_type":"code","source":["# lag values to manually backfill label (bfill =7)\nmy_window = Window.partitionBy('machineID').orderBy(labeled_features.dt_truncated.desc())\n\n# Create the previous 7 days \nlabeled_features = (labeled_features.withColumn(\"prev_value1\", \n                                                F.lag(labeled_features.failure).\n                                                over(my_window)).fillna(0))\nlabeled_features = (labeled_features.withColumn(\"prev_value2\", \n                                                F.lag(labeled_features.prev_value1).\n                                                over(my_window)).fillna(0))\nlabeled_features = (labeled_features.withColumn(\"prev_value3\", \n                                                F.lag(labeled_features.prev_value2).\n                                                over(my_window)).fillna(0))\nlabeled_features = (labeled_features.withColumn(\"prev_value4\", \n                                                F.lag(labeled_features.prev_value3).\n                                                over(my_window)).fillna(0)) \nlabeled_features = (labeled_features.withColumn(\"prev_value5\", \n                                                F.lag(labeled_features.prev_value4).\n                                                over(my_window)).fillna(0)) \nlabeled_features = (labeled_features.withColumn(\"prev_value6\", \n                                                F.lag(labeled_features.prev_value5).\n                                                over(my_window)).fillna(0))\nlabeled_features = (labeled_features.withColumn(\"prev_value7\", \n                                                F.lag(labeled_features.prev_value6).\n                                                over(my_window)).fillna(0))\n\n# Create a label features\nlabeled_features = (labeled_features.withColumn('label', labeled_features.failure + \n                                                labeled_features.prev_value1 +\n                                                labeled_features.prev_value2 +\n                                                labeled_features.prev_value3 +\n                                                labeled_features.prev_value4 +\n                                                labeled_features.prev_value5 + \n                                                labeled_features.prev_value6 + \n                                                labeled_features.prev_value7))\n\n# Restrict the label to be on the range of 0:4, and remove extra columns\nlabeled_features = (labeled_features.withColumn('label_e', F.when(col('label') > 4, 4.0)\n                                                .otherwise(col('label')))\n                    .drop(labeled_features.prev_value1).drop(labeled_features.prev_value2)\n                    .drop(labeled_features.prev_value3).drop(labeled_features.prev_value4)\n                    .drop(labeled_features.prev_value5).drop(labeled_features.prev_value6)\n                    .drop(labeled_features.prev_value7).drop(labeled_features.label))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">96045\n<span class=\"ansired\">Out[</span><span class=\"ansired\">37</span><span class=\"ansired\">]: </span>\n   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n0         26 2016-01-01 12:00:00           164.275746             471.649368   \n1         26 2016-01-01 00:00:00           165.726644             456.042954   \n2         26 2015-12-31 12:00:00           168.518292             447.129760   \n3         26 2015-12-31 00:00:00           166.475756             441.837328   \n4         26 2015-12-30 12:00:00           169.697142             436.694922   \n5         26 2015-12-30 00:00:00           170.994850             456.078917   \n6         26 2015-12-29 12:00:00           171.108399             440.680414   \n7         26 2015-12-29 00:00:00           167.499443             432.128254   \n8         26 2015-12-28 12:00:00           164.290096             460.841581   \n9         26 2015-12-28 00:00:00           170.786501             446.118612   \n\n   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n0               127.520119                 42.709311           166.077766   \n1               125.058244                 41.195437           167.122468   \n2               117.390746                 40.746361           167.497024   \n3                98.123529                 41.469891           168.086449   \n4                97.624766                 41.881681           170.345996   \n5               103.350856                 40.597715           171.051625   \n6               101.546768                 39.062075           169.303921   \n7               103.699874                 40.369184           165.894769   \n8               101.147246                 41.261270           167.538298   \n9                99.955372                 41.346260           169.011702   \n\n   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n0             460.249765               125.377577                 41.343086   \n1             451.586357               121.224495                 40.970899   \n2             444.483544               107.757137                 41.108126   \n3             439.266125                97.874147                 41.675786   \n4             446.386919               100.487811                 41.239698   \n5             448.379665               102.448812                 39.829895   \n6             436.404334               102.623321                 39.715629   \n7             446.484917               102.423560                 40.815227   \n8             453.480096               100.551309                 41.303765   \n9             451.989171               100.539022                 41.103588   \n\n    ...     error5sum_rollingmean_24  comp1sum  comp2sum  comp3sum  comp4sum  \\\n0   ...                          0.0       0.0       0.0       0.0       0.0   \n1   ...                          0.0       0.0       0.0       0.0       0.0   \n2   ...                          0.0       0.0       0.0       0.0       0.0   \n3   ...                          0.0       0.0       0.0       0.0       0.0   \n4   ...                          0.0       0.0       0.0       0.0       0.0   \n5   ...                          0.0       0.0       0.0       0.0       0.0   \n6   ...                          0.0       0.0       0.0       0.0       0.0   \n7   ...                          0.0       0.0       0.0       0.0       0.0   \n8   ...                          0.0       0.0       0.0       0.0       0.0   \n9   ...                          0.0       0.0       0.0       0.0       0.0   \n\n    model  age    model_encoded  failure  label_e  \n0  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n1  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n2  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n3  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n4  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n5  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n6  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n7  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n8  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n9  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n\n[10 rows x 40 columns]\n</div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["To verify the label construction, we plot a sample of four machines over the data set life time. We expect the labels to cluster for each component, since there are 7 day windows of \"fail\". We have omitted the healthy labels, as they are uninformative. Since the labels are actually classes, the plot as four distinct values on the y-axis."],"metadata":{}},{"cell_type":"markdown","source":["Here we see that most of the days are marked as healthy (label = 0 are omitted for plot performance, though the dates are still accurate). Each of the four machines have multiple failures over the course of the dataset. Each labeled failure includes the date of failure and the previous seven days, all are marked with the number indicating the component that failed. \n\nThe goal of the model will be to predict when a failure will occur and which component will fail simultaneously. This will be a multiclass classification problem, though we could pivot the data to individually predict binary failure of a component instead of a machine."],"metadata":{}},{"cell_type":"markdown","source":["## Write the feature data to cloud storage\n\nWrite the final labeled feature data as parquet file an Azure blob storage container. For technical details, see:\nhttps://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md"],"metadata":{"collapsed":true}},{"cell_type":"code","source":["labeled_features.write.mode('overwrite').saveAsTable(dbutils.widgets.get(\"FEATURES_TABLE\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Feature engineering final dataset files saved!\nFull run took 4.82 minutes\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["# Conclusion\n\nThe next step is to build and compare machine learning models using the feature data set we have just created. The `Code\\3_model_building.ipynb` notebook works through building a Decision Tree Classifier and a Random Forest Classifier using this data set."],"metadata":{"collapsed":true}}],"metadata":{"kernelspec":{"display_name":"PredictiveMaintenance dlvmjme","language":"python","name":"predictivemaintenance_dlvmjme"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":"3"},"version":"3.5.2","nbconvert_exporter":"python","file_extension":".py"},"name":"2_feature_engineering","notebookId":1688287220131104},"nbformat":4,"nbformat_minor":0}
