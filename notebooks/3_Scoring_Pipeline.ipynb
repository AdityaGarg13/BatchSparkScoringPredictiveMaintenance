{"cells":[{"cell_type":"markdown","source":["# Step 3: Create a Scoring Pipeline\n\nThe scoring pipeline consists of two steps:\n\n  1. Transform the raw data into a scoring data set\n  2. Score the scoring data set.\n  \nWe assume that new data is arriving into the data store as it's generated. The scoring workflow would poll the data store for new data on whatever schedule is convenient (realtime, hourly, daily...), transform and manipulate the new data just as was done for the training step, then predict the label for the new observations. \n\nBasically, we can run the feature engineering notebook (`./notebooks/2a_feature_engineering`) with the correct parameters to get the new data out, and transform the data into observation format the model expects. Second, we run the scoring notebook (`./notebooks/3a_model_scoring`) to generate predictions for each of those observations. \n\nWe choose the model created in the model training pipeline, and store the predictions in the results_data table. The"],"metadata":{}},{"cell_type":"code","source":["import pyspark.sql.functions as F\nfrom pyspark.sql import SparkSession\n\n# The scoring uses the same feature engineering script used to train the model\nscoring_table = 'HPscoring_input'\nresults_table = 'HPresults_output'\nmodel_type = 'RandomForest' # Use 'DecisionTree' or 'RandomForest'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["dbutils.widgets.removeAll()\ndbutils.widgets.text(\"results_data\", results_table)\n\ndbutils.widgets.text(\"model_type\", model_type)\n\ndbutils.widgets.text(\"start_date\", '2015-11-15')\n\ndbutils.widgets.text(\"to_date\", '2016-04-30')\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["dbutils.notebook.run(\"2a_feature_engineering\", 600, {\"features_table\": scoring_table, \n                                                     \"start_date\": dbutils.widgets.get(\"start_date\"), \n                                                     \"to_date\": dbutils.widgets.get(\"to_date\")})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["dbutils.notebook.run(\"3a_model_scoring\", 600, {\"scoring_data\": scoring_table, \n                                               \"results_data\": dbutils.widgets.get(\"results_data\"), \n                                               \"model_type\": dbutils.widgets.get(\"model_type\")})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Since we created the scoring data set, we should remove it to keep things clean.\nspark = SparkSession.builder.getOrCreate()\ntelemetry = spark.sql(\"DROP TABLE \" + scoring_table)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6}],"metadata":{"name":"Scoring Workflow","notebookId":3882718389074282},"nbformat":4,"nbformat_minor":0}
