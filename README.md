

# Batch scoring of SPARK machine learning models 

## Overview
This scenario demonstrates the scoring of a SPARK machine learning model in batch mode on Azure Databricks. The model is constructed for a predictive maintenance scenario where we classify machine sensor readings into a periodic prediction of overall healthy and requiring maintenance for a series of machine components. The resulting supervised multi-class model scores batches of new observations through a regularly scheduled Azure Databricks notebook.

For this scenario, “Input Data” in the architecture diagram refers to a set of five simulated data sets related to realistic machine operating conditions. The scenario is uses methods from the PySpark MLlib machine learning library but can be generalized to use any Python or R model hosted on Azure Databricks to make real-time predictions.

## Design

The 10K foot view of the architecture that includes things like (DockerHub/VM/etc) to give a visual on what the overall design is.

This should also include supported platforms.

# Prerequisites

What do you need to have at your disposal?

## Databricks cluster

https://ms.portal.azure.com/#create/Microsoft.Databricks

## Databricks CLI

https://github.com/databricks/databricks-cli

# Setup

Login to databricks CLI. 

## Import Notebooks

`databricks workspace import_dir notebooks /Users/<uname@example.com>/notebooks`

## Get cluster Id

`databricks clusters list`

## Setup databricks jobs 

### Ingest data

`databricks jobs create --json-file jobs/01_CreateDataIngestion.json`

`databricks jobs run-now --job-id <jobID>`

### Feature engineering

`databricks jobs create --json-file jobs/02_CreateFeatureEngineering.json`

`databricks jobs run-now --job-id <jobID>`

We supply parameters using the `--notebook-params` command.

`databricks jobs run-now --job-id <jobID> --notebook-params {"FEATURES_TABLE":"testing_data","Start_Date":"2015-11-15","zEnd_Date":"2017-01-01"}`

On windows command line, we need to escape the double quotes:

`databricks jobs run-now --job-id <jobID> --notebook-params {\"FEATURES_TABLE\":\"testing_data\",\"Start_Date\":\"2015-11-15\",\"zEnd_Date\":\"2017-01-01\"}`

### Create the model

`databricks jobs create --json-file jobs/03_CreateModelBuilding.json`

`databricks jobs run-now --job-id <jobID>`

`databricks jobs run-now --job-id <jobID> --notebook-params {\"model\":\"DecisionTree\"}`

If you already have a SPARK model saved in Parquet format, you can copy using the CLI command `dbfs cp <SRC> <DST>`.

`dbfs cp  -r model.pqt dbfs:/storage/models/model.pqt`

## Load the scoring job

We need to create the dataset we'll score

`databricks jobs run-now --job-id <jobID> --notebook-params {\"FEATURES_TABLE\":\"scoring_input\",\"Start_Date\":\"2015-12-30\",\"zEnd_Date\":\"2016-04-30\"}`

The load the scoring job

`databricks jobs create --json-file jobs/04_CreateModelScoring.json`

Then run the job.

`databricks jobs run-now --job-id <jobID>`

# Steps

Instructions on where to go (first notebook or folder)

# Cleaning up

Where applicable, what does the user have to manually scrub to clean it.

# Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

### Author: 
John Ehrlinger <john.ehrlinger@microsoft.com>
